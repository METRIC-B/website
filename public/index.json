[{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536444000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536444000,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":["Tom Hardwicke","Steven Goodman"],"categories":null,"content":"","date":1582239600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582239600,"objectID":"444f165e85eaf58e451cc231d73e8b0b","permalink":"/publication/stat-review-biomed/","publishdate":"2020-02-21T00:00:00+01:00","relpermalink":"/publication/stat-review-biomed/","section":"publication","summary":"Scientific claims in biomedical research are typically derived from statistical analyses. However, misuse and misunderstanding of statistical procedures and results permeates the biomedical literature, affecting the validity of those claims. One approach journals have taken to address this issue is to enlist expert statistical reviewers. How many journals do this, how statistical review is incorporated, and how its value is perceived by editors is of interest. Here we report an expanded version of a survey conducted more than 20 years ago by Goodman and colleagues (1998) with the intention of characterizing contemporary statistical review policies at leading biomedical journals. We received eligible responses from 107 of 364 (28%) journals surveyed, across 57 fields, mostly from editors in chief. 34% (36/107) rarely or never use specialized statistical review, 34% (36/107) used it for 10-50% of their articles and 23% used it for all articles. These numbers have changed little since 1998 in spite of dramatically increased concern about research validity. The vast majority of editors regarded statistical review as having substantial incremental value beyond regular peer review and expressed comparatively little concern about the potential increase in reviewing time, cost, and difficulty identifying suitable statistical reviewers. Improved statistical education of researchers and different ways of employing statistical expertise are needed. Several proposals are discussed.","tags":null,"title":"How often do leading biomedical journals use statistical experts to evaluate statistical methods? The results of a survey.","type":"publication"},{"authors":["Tom Hardwicke","Joshua Wallach","Mallory Kidwell","Theiss Bendixen","Sophia Crüwell","John Ioannidis"],"categories":null,"content":"","date":1582066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582066800,"objectID":"ae01da308324280160856406b2c10ee2","permalink":"/publication/socsci_transparency2014-2017/","publishdate":"2020-02-19T00:00:00+01:00","relpermalink":"/publication/socsci_transparency2014-2017/","section":"publication","summary":"Serious concerns about research quality have catalyzed a number of reform initiatives intended to improve transparency and reproducibility and thus facilitate self-correction, increase efficiency, and enhance research credibility. Meta-research has evaluated the merits of individual initiatives; however, this may not capture broader trends reflecting the cumulative contribution of these efforts. In this study, we evaluated a broad range of indicators related to transparency and reproducibility in a random sample of 198 articles published in the social sciences between 2014 and 2017. Few articles indicated availability of materials (15/96, 16% [95% confidence interval, 9% to 23%]), protocols (0/103), raw data (8/103, 8% [2% to 15%]), or analysis scripts (3/103, 3% [1% to 6%]), and no studies were pre-registered (0/103). Some articles explicitly disclosed funding sources (or lack of; 72/179, 40% [33% to 48%]) and some declared no conflicts of interest (32/179, 18% [13% to 24%]). Replication studies were rare (2/103, 2% [0% to 4%]). Few studies were included in evidence synthesis via systematic review (6/96, 6% [3% to 11%]) or meta-analysis (2/96, 2% [0% to 4%]). Slightly less than half the articles were publicly available (95/198, 48% [41% to 55%]). Minimal adoption of transparency and reproducibility-related research practices could be undermining the credibility and efficiency of social science research. The present study establishes a baseline that can be revisited in the future to assess progress.","tags":null,"title":"An empirical assessment of transparency and reproducibility-related research practices in the social sciences (2014-2017)","type":"publication"},{"authors":["Tom Hardwicke"],"categories":null,"content":"","date":1578697200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578697200,"objectID":"cfdee2f50fd10a492e7790470fed8a84","permalink":"/talk/tomhardwicke/2020/frankfurt/","publishdate":"2020-01-11T00:00:00+01:00","relpermalink":"/talk/tomhardwicke/2020/frankfurt/","section":"talk","summary":"","tags":[],"title":"What is this thing called open science?","type":"talk"},{"authors":["Tom Hardwicke"],"categories":null,"content":"","date":1578697200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578697200,"objectID":"1ef01b20dbbd08314fc90891bb32f03f","permalink":"/talk/tomhardwicke/2020/jena/","publishdate":"2020-01-11T00:00:00+01:00","relpermalink":"/talk/tomhardwicke/2020/jena/","section":"talk","summary":"","tags":[],"title":"What is this thing called open science?","type":"talk"},{"authors":["Tom Hardwicke","Robert Thibault","Jessica Kosie","Joshua Wallach","Mallory Kidwell","John Ioannidis"],"categories":null,"content":"","date":1578265200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578265200,"objectID":"d66be42ba5ffdec82818bbb9f7a3c927","permalink":"/publication/psych_transparency2014-2017/","publishdate":"2020-01-06T00:00:00+01:00","relpermalink":"/publication/psych_transparency2014-2017/","section":"publication","summary":"Psychological science is navigating an unprecedented period of introspection about the credibility and utility of its research. A number of reform initiatives aimed at increasing adoption of transparency and reproducibility-related research practices appear to have been effective in specific contexts; however, their broader, collective impact amidst a wider discussion about research credibility and reproducibility is largely unknown. In the present study, we estimated the prevalence of several transparency and reproducibility-related indicators in the psychology literature published between 2014-2017 by manually assessing these indicators in a random sample of 250 articles. Over half of the articles we examined were publicly available (154/237, 65% [95% confidence interval, 59% to 71%]). However, sharing of important research resources such as materials (26/183, 14% [10% to 19%]), study protocols (0/188, 0% [0% to 1%]), raw data (4/188, 2% [1% to 4%]), and analysis scripts (1/188, 1% [0% to 1%]) was rare. Pre-registration was also uncommon (5/188, 3% [1% to 5%]). Although many articles included a funding disclosure statement (142/228, 62% [56% to 69%]), conflict of interest disclosure statements were less common (88/228, 39% [32% to 45%]). Replication studies were rare (10/188, 5% [3% to 8%]) and few studies were included in systematic reviews (21/183, 11% [8% to 16%]) or meta-analyses (12/183, 7% [4% to 10%]). Overall, the findings suggest that transparent and reproducibility-related research practices are far from routine in psychological science. Future studies can use the present findings as a baseline to assess progress towards increasing the credibility and utility of psychology research.","tags":null,"title":"Estimating the prevalance of transparency and reproducibility-related research practices in psychology (2014-2017)","type":"publication"},{"authors":["Sophia Crüwell","Angelika Stefan","Nathan Evans"],"categories":null,"content":"","date":1566770400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566770400,"objectID":"eba0ca3f0444e1cd5cc3568167d84164","permalink":"/publication/robust-standards-cogsci/","publishdate":"2019-08-26T00:00:00+02:00","relpermalink":"/publication/robust-standards-cogsci/","section":"publication","summary":"Recent discussions within the mathematical psychology community have focused on how Open Science practices may apply to cognitive modelling. Lee et al. (2019) sketched an initial approach for adapting Open Science practices that have been developed for experimental psychology research to the unique needs of cognitive modelling. While we welcome the general proposal of Lee et al. (2019), we believe a more fine-grained view is necessary to accommodate the adoption of Open Science practices in the diverse areas of cognitive modelling. Firstly, we suggest a categorization for the diverse types of cognitive modelling, which we argue will allow researchers to more clearly adapt Open Science practices to different types of cognitive modelling. Secondly, we consider the feasibility and usefulness of preregistration and lab notebooks for each of these categories and address potential objections to preregistration in cognitive modelling. Finally, we separate several cognitive modelling concepts that we believe Lee et al. (2019) conflated, which should allow for greater consistency and transparency in the modelling process. At a general level, we propose a framework that emphasizes local consistency in approaches while allowing for global diversity in modelling practices.","tags":null,"title":"Robust Standards in Cognitive Science","type":"publication"},{"authors":["Tom Hardwicke","Michael Frank","Simine Vazire","Steven Goodman"],"categories":null,"content":"","date":1562104800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562104800,"objectID":"ff879a586558cf858d75a383995109cc","permalink":"/publication/stat-review-psych/","publishdate":"2019-07-03T00:00:00+02:00","relpermalink":"/publication/stat-review-psych/","section":"publication","summary":"Readers of peer-reviewed research may assume that the reported statistical analyses supporting scientific claims have been closely scrutinized and surpass a high-quality threshold. However, widespread misunderstanding and misuse of statistical concepts and methods suggests that suboptimal or erroneous statistical practice is routinely overlooked during peer review in psychology. Here, we explore whether psychology journals could ameliorate some of the field’s statistical ailments by adopting specialized statistical review: a focused technical assessment, performed by statistical experts, that addresses the analysis and presentation of quantitative information and supplements regular peer review. We discuss evidence from a recent survey of journal editors suggesting that specialized statistical review may be unusual in psychology journals and is regarded by many editors as unnecessary. We contrast these views with those in the biomedical domain, where statistical review has been considered a partial preventive measure against the improper use of statistics since the late 1970s. We suggest that the current “credibility revolution” presents an opportune occasion for psychology journals to consider adopting specialized statistical review.","tags":null,"title":"Should psychology journals adopt specialized statistical review?","type":"publication"},{"authors":["Tom Hardwicke","John Ioannidis"],"categories":null,"content":"","date":1561672800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561672800,"objectID":"95cfd911df047a16e42ea35718773ae0","permalink":"/publication/rss-survey/","publishdate":"2019-06-28T00:00:00+02:00","relpermalink":"/publication/rss-survey/","section":"publication","summary":"Petitions have a long history of being used for political, social, ethical, and injustice issues, however, it is unclear how/whether they should be implemented in scientific argumentation. Recently, an extremely influential commentary published in Nature (Amrhein et al., 2019) calling for the abandonment of “statistical significance” was signed by 854 scientists. We surveyed signatories and observed substantial heterogeneity in respondents’ perceptions of the petition process, motivations for signing, and views on aspects of abandoning statistical significance. The top-cited signatories were strongly concentrated in a few scientific fields. In a random sample of 100 signatories, 62 published at least one paper in 2018 using statistical inference and most of them had used the phrase “statistical significance”. When scientists sign petitions, they may have variable views on important aspects and it is useful to understand this diversity.","tags":null,"title":"Petitions in scientific argumentation: dissecting the request to retire statistical significance","type":"publication"},{"authors":["Tom Hardwicke","Stylianos Serghiou","Perrine Janiaud","Valentin Danchev","Sophia Crüwell","Steven Goodman","John Ioannidis"],"categories":null,"content":"","date":1560376800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560376800,"objectID":"c47bdc139b5edb0751cb659860d289b6","permalink":"/publication/calibrating-meta-research/","publishdate":"2019-06-13T00:00:00+02:00","relpermalink":"/publication/calibrating-meta-research/","section":"publication","summary":"Whilst some scientists study insects, molecules, brains, or clouds, other scientists study science itself. Meta-research, or “research-on-research”, is a burgeoning discipline that investigates efficiency, quality, and bias in the scientific ecosystem, topics that have become especially relevant amid widespread concerns about the credibility of the scientific literature. Meta-research may help calibrate the scientific ecosystem towards higher standards by providing empirical evidence that informs the iterative generation and refinement of reform initiatives. We introduce a translational framework that involves (1) identifying problems; (2) investigating problems; (3) developing solutions; and (4) evaluating solutions. In each of these areas, we review key meta-research endeavors and discuss several examples of prior and ongoing work. The scientific ecosystem is perpetually evolving; the discipline of meta-research presents an opportunity to use empirical evidence to guide its development and maximize its potential.","tags":null,"title":"Calibrating the scientific ecosystem through meta-research","type":"publication"},{"authors":["Brian Nosek","Emorie Beck","Lorne Campbell","Jessica Flake","Tom Hardwicke","David Mellor","Anna van ’t Veer","Simine Vazire"],"categories":null,"content":"","date":1560376800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560376800,"objectID":"6f01c8bbbbfef903fc895f9d05b97cb8","permalink":"/publication/prereg-is-hard/","publishdate":"2019-06-13T00:00:00+02:00","relpermalink":"/publication/prereg-is-hard/","section":"publication","summary":"Preregistration clarifies the distinction between planned and unplanned research by reducing unnoticed flexibility. This improves credibility of findings and calibration of uncertainty. However, making decisions before conducting analyses requires practice. During report writing, respecting both what was planned and what actually happened requires good judgment and humility in making claims.","tags":null,"title":"Preregistration is hard, and worthwhile","type":"publication"},{"authors":["Tom Hardwicke"],"categories":null,"content":"","date":1548716400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548716400,"objectID":"05663287af783965a12da8e10887cd48","permalink":"/talk/tomhardwicke/2019/zpid/","publishdate":"2019-01-29T00:00:00+01:00","relpermalink":"/talk/tomhardwicke/2019/zpid/","section":"talk","summary":"","tags":[],"title":"Calibrating the scientific ecosystem through meta research","type":"talk"},{"authors":["John Ioannidis"],"categories":null,"content":"","date":1548716400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548716400,"objectID":"7a2a980e2e9e6a9be0228362a7e30941","permalink":"/talk/johnioannidis/2019/metricb/","publishdate":"2019-01-29T00:00:00+01:00","relpermalink":"/talk/johnioannidis/2019/metricb/","section":"talk","summary":"[Live recording](https://www.youtube.com/watch?time_continue=12\u0026v=i4XjP0FaeRg) at the opening of METRIC-Berlin.","tags":[],"title":"Scientific evidence: reproducible and useful","type":"talk"},{"authors":["Tom Hardwicke"],"categories":null,"content":"","date":1541545200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541545200,"objectID":"42623471d070740632eac6ca625c89d8","permalink":"/talk/tomhardwicke/2018/bankofengland/","publishdate":"2018-11-07T00:00:00+01:00","relpermalink":"/talk/tomhardwicke/2018/bankofengland/","section":"talk","summary":"The scientific method has proven its worth on innumerable occasions. However, serious questions have been raised about the credibility of many published findings and a great deal of research effort may be wasted. Scientists are only human and operate within an ecosystem that can exacerbate, rather than protect against, the infusion of bias and error into the research process. Widespread lack of transparency and non-sharing of fundamental research artifacts, such as raw data, analysis scripts, and study protocols, impedes self-correction activities that might otherwise maintain the veracity of the literature. But the scientific ecosystem is shifting and evolving. New initiatives promoting open data, pre-registration, collaboration, replication, and reproducibility are starting to bear fruit. Innovation and cross-fertilization of ideas between disciplines can accelerate progress, but careful evaluation and monitoring through meta-research will be necessary to appropriately calibrate solutions and avoid adverse effects. A healthier scientific ecosystem is on the horizon.","tags":[],"title":"Rehabilitating the scientific ecosystem","type":"talk"},{"authors":["John Ioannidis"],"categories":null,"content":"","date":1541545200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541545200,"objectID":"9b32506f83da3cd242cd2b612bff1ad9","permalink":"/talk/johnioannidis/2016/","publishdate":"2018-11-07T00:00:00+01:00","relpermalink":"/talk/johnioannidis/2016/","section":"talk","summary":"[Live recording](https://www.youtube.com/watch?v=xGLF6olIZYY) of John Ioannidis' lecture about 'Reproducibility and improving research practices'. It was held on 12 May 2016 in Berlin and organized by Berlin Institute of Health as first lecture in the new series 'BIH Annual Special Lecture'.","tags":[],"title":"Reproducibility and improving research practices","type":"talk"},{"authors":["Tom Hardwicke","John Ioannidis"],"categories":null,"content":"","date":1541026800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541026800,"objectID":"f356f5ed075c25d79aadbe579a75963b","permalink":"/publication/registered-reports-universe/","publishdate":"2018-11-01T00:00:00+01:00","relpermalink":"/publication/registered-reports-universe/","section":"publication","summary":"Registered reports present a substantial departure from traditional publishing models with the goal of enhancing the transparency and credibility of the scientific literature. We map the evolving universe of registered reports to assess their growth, implementation and shortcomings at journals across scientific disciplines.","tags":null,"title":"Mapping the universe of registered reports","type":"publication"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536444000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536444000,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/tutorial/example/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["Tom Hardwicke","John Ioannidis"],"categories":null,"content":"","date":1533160800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533160800,"objectID":"ebfb9570fe9bf9e43cd36e2e19ce1421","permalink":"/publication/data-ark/","publishdate":"2018-08-02T00:00:00+02:00","relpermalink":"/publication/data-ark/","section":"publication","summary":"The vast majority of scientific articles published to-date have not been accompanied by concomitant publication of the underlying research data upon which they are based. This state of affairs precludes the routine re-use and re-analysis of research data, undermining the efficiency of the scientific enterprise, and compromising the credibility of claims that cannot be independently verified. It may be especially important to make data available for the most influential studies that have provided a foundation for subsequent research and theory development. Therefore, we launched an initiative—the Data Ark—to examine whether we could retrospectively enhance the preservation and accessibility of important scientific data. Here we report the outcome of our efforts to retrieve, preserve, and liberate data from 111 of the most highly-cited articles published in psychology and psychiatry between 2006–2011 (n = 48) and 2014–2016 (n = 63). Most data sets were not made available (76/111, 68%, 95% CI [60, 77]), some were only made available with restrictions (20/111, 18%, 95% CI [10, 27]), and few were made available in a completely unrestricted form (15/111, 14%, 95% CI [5, 22]). Where extant data sharing systems were in place, they usually (17/22, 77%, 95% CI [54, 91]) did not allow unrestricted access. Authors reported several barriers to data sharing, including issues related to data ownership and ethical concerns. The Data Ark initiative could help preserve and liberate important scientific data, surface barriers to data sharing, and advance community discussions on data stewardship.","tags":null,"title":"Populating The Data Ark: An attempt to obtain and preserve data from the most highly-cited psychology and psychiatry articles","type":"publication"},{"authors":[],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461103200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515798000,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2016-04-20T00:00:00+02:00","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"10065deaa3098b0da91b78b48d0efc71","permalink":"/post/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/post/2015-07-23-r-rmarkdown/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":null,"categories":null,"content":"John P.A. Ioannidis, MD, DSc is the C.F. Rehnborg Professor in Disease Prevention, and Professor of Medicine, of Health Research and Policy, of Biomedical Data Science, and of Statistics at Stanford University and a BIH Visiting Fellow funded by the Stiftung Charité and the Einstein Foundation Berlin. Dr. Ioannidis is internationally recognized as a leader in empirical studies assessing biases, replication, and reliability of research findings in biomedicine and beyond. He has received numerous awards and honorary doctorates and titles and he is a member of the US National Academy of Medicine and of the European Academy of Sciences and Arts. He has served as President of the Society for Research Synthesis Methodology, Senior Advisor for Knowledge Integration at the National Cancer Institute, editorial board member of 30 leading international journals and Editor-in-Chief of the European Journal of Clinical Investigation. He is one of the most-cited scientists worldwide. His PLoS Medicine paper on “Why most Published Research Findings are False,” has been the most-accessed article in the history of Public Library of Science with over 2.5 million hits.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0e01e4850a32aecef979184872c2e467","permalink":"/team/johnioannidis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/team/johnioannidis/","section":"team","summary":"John P.A. Ioannidis, MD, DSc is the C.F. Rehnborg Professor in Disease Prevention, and Professor of Medicine, of Health Research and Policy, of Biomedical Data Science, and of Statistics at Stanford University and a BIH Visiting Fellow funded by the Stiftung Charité and the Einstein Foundation Berlin. Dr. Ioannidis is internationally recognized as a leader in empirical studies assessing biases, replication, and reliability of research findings in biomedicine and beyond. He has received numerous awards and honorary doctorates and titles and he is a member of the US National Academy of Medicine and of the European Academy of Sciences and Arts.","tags":null,"title":" John Ioannidis","type":"team"},{"authors":null,"categories":null,"content":"Dr Tom Hardwicke completed a BSc in Psychology at Cardiff University, MRes in Brain Imaging and Cognitive Neuroscience at The University of Birmingham, and PhD in Experimental Psychology at University College London before joining the Meta-Research Innovation Center at Stanford (METRICS) as a Postdoctoral Fellow in 2017. After two happy years in the Californian sunshine, Tom is now heading across the pond to Germany in January 2019 to set up the Meta-Research Innovation Center Berlin (METRIC-Berlin). Tom\u0026rsquo;s work involves empirical assessments of bias and reproduciblity, developing tools and guidelines to improve research transparency and mitigate error, and evaluating policies and initiatives intended to improve the quality and efficiency of the scientific endeavour, such as pre-registration, Registered Reports, and open data.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b15bab367d27dfe2422e7543dd874028","permalink":"/team/tomhardwicke/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/team/tomhardwicke/","section":"team","summary":"Dr Tom Hardwicke completed a BSc in Psychology at Cardiff University, MRes in Brain Imaging and Cognitive Neuroscience at The University of Birmingham, and PhD in Experimental Psychology at University College London before joining the Meta-Research Innovation Center at Stanford (METRICS) as a Postdoctoral Fellow in 2017. After two happy years in the Californian sunshine, Tom is now heading across the pond to Germany in January 2019 to set up the Meta-Research Innovation Center Berlin (METRIC-Berlin).","tags":null,"title":" Tom Hardwicke","type":"team"},{"authors":null,"categories":[],"content":" Podcasts  The ORION Open Science Podcast A Metric for Optimism: John Ioannidis on Reproducibility, Preregistration, and Data Sharing.\n  STEM-Talk John Ioannidis discusses his paper ‘Why most published research findings are false’.\n  The Recommended Dose John Ioannidis talks to Ray Moynihan about the far-reaching implications of his paper ‘Why most published research findings are false’ for people both inside and outside the world of health.\n  Blog posts  The Attrition of the Modern Scholarly Record Tom Hardwicke argues that an extensive and ongoing attrition of the modern scholarly record is impeding important research activties and introduces the Data Ark project: an attempt to retrieve, preserve, and liberate the influential scientific data.\n  Are open data actually reusable? Tom Hardwicke discusses why open data alone will not be enough to achieve the benefits envisioned by proponents of data sharing.\n  Where do the numbers published in scientific articles come from? Tom Hardwicke describes how a recent attempt to reproduce findings reported in a sample of psychology articles revealed analysis pipelines peppered with errors.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9f2969fc6649b6a4eb9186b3521f01b6","permalink":"/media/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/media/","section":"","summary":"Podcasts  The ORION Open Science Podcast A Metric for Optimism: John Ioannidis on Reproducibility, Preregistration, and Data Sharing.\n  STEM-Talk John Ioannidis discusses his paper ‘Why most published research findings are false’.\n  The Recommended Dose John Ioannidis talks to Ray Moynihan about the far-reaching implications of his paper ‘Why most published research findings are false’ for people both inside and outside the world of health.","tags":[],"title":"Media","type":"static"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Sophia Crüwell completed a BA in Natural Sciences (Part II) and Philosophy (Part I) at the University of Cambridge, and an MSc (Research) at the University of Amsterdam, where she majored in Psychological Methods and Statistics and minored in Logic. She has just started her PhD in Metascience with METRIC-Berlin and plans to focus on researching incentive structures. You can also find her co-hosting the Open Science focussed podcast ReproducibiliTea.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e5bd752a655a4c0e06d762579e8afeb5","permalink":"/team/sophiacruwell/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/team/sophiacruwell/","section":"team","summary":"Sophia Crüwell completed a BA in Natural Sciences (Part II) and Philosophy (Part I) at the University of Cambridge, and an MSc (Research) at the University of Amsterdam, where she majored in Psychological Methods and Statistics and minored in Logic. She has just started her PhD in Metascience with METRIC-Berlin and plans to focus on researching incentive structures. You can also find her co-hosting the Open Science focussed podcast ReproducibiliTea.","tags":null,"title":"Sophia Crüwell","type":"team"}]